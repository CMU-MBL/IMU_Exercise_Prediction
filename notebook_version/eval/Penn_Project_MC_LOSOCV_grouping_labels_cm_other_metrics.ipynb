{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIza75t_gac7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a24f07-cdcd-4662-98e2-822cd472271c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 28 02:23:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "3TIoO_7KYa_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access to the Google Drive folder"
      ],
      "metadata": {
        "id": "rB0gQjpjYdIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requirements\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZvIuhv0aYcAC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb712b4-4350-4017-faee-11d425f4df9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library"
      ],
      "metadata": {
        "id": "x7YMapYXZADc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "x-AIuAO0ZA8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants"
      ],
      "metadata": {
        "id": "mokqv4QQZDe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ID_EXERCISE_LABEL = -3\n",
        "ID_CLUSTER_LABEL = -2\n",
        "ID_SUBJECT_LABEL = -1\n",
        "\n",
        "NORM_SAMPLE_LENGTH = 100\n",
        "# --- Enable below for results of all 10 IMUs --- #\n",
        "CONSIDERED_IMU_POSITION = ['LeftShank', 'RightShank', 'LeftThigh', 'RightThigh', 'Pelvis', 'Chest', 'LeftFoot', 'RightFoot', 'LeftWrist', 'RightWrist']\n",
        "# # --- Enable below for a subset of specific IMUs, remember to change depending on use --- #\n",
        "# CONSIDERED_IMU_POSITION = ['LeftShank', 'RightShank', 'LeftThigh', 'RightThigh', 'Pelvis', 'LeftFoot', 'RightFoot']\n",
        "NOT_CONSIDERED_INFO = ['Time', 'Orientation', 'Magnetometer'] # not use these information\n",
        "# NOT_CONSIDERED_INFO = ['Time', 'Orientation', 'Accelerometer', 'Magnetometer'] # additionally remove accelerometer info\n",
        "# NOT_CONSIDERED_INFO = ['Time', 'Orientation', 'Gyroscope', 'Magnetometer'] # additionally remove gyroscope info\n",
        "NUM_SENSOR_INFO = 2 # gyroscope and acceleration\n",
        "# NUM_SENSOR_INFO = 1 # gyroscope or acceleration\n",
        "NUM_AX_PER_SENSOR = 3 # x-, y-, and z-\n",
        "\n",
        "NUM_SUBJECT = 20"
      ],
      "metadata": {
        "id": "aJtzPdxEZEC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster from the clustering analysis\n",
        "CLUSTER = [[0, 3, 6, 7, 24, 27, 28, 29, 30, 35],  # cluster 0\n",
        "           [13, 14, 15, 16, 25],                  # cluster 1\n",
        "           [12, 17, 20, 31, 32, 33, 34, 36],      # cluster 2\n",
        "           [22],                                  # cluster 3\n",
        "           [18, 19, 23, 26],                      # cluster 4\n",
        "           [21],                                  # cluster 5\n",
        "           [10, 11],                              # cluster 6\n",
        "           [8, 9],                                # cluster 7\n",
        "           [4, 5],                                # cluster 8\n",
        "           [1, 2]]                                # cluster 9"
      ],
      "metadata": {
        "id": "Qze9THoXhqqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model hyper-parameters --- #\n",
        "# Fixed parameters\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_EPOCHS = 30\n",
        "ADAM_WEIGHT_DECAY = 1e-2\n",
        "LEARNING_RATE_REDUCTION_FACTOR = 0.5\n",
        "\n",
        "# CONV_NUM_IN = 60 # temporarily hardcoded\n",
        "num_imu = len(CONSIDERED_IMU_POSITION)\n",
        "conv_num_in = num_imu*NUM_SENSOR_INFO*NUM_AX_PER_SENSOR\n",
        "\n",
        "# Recorded tuning parameters\n",
        "# For all 10 IMUs\n",
        "# format: [batch_size, conv_num_out, kernel_size, stride_length, pool_size]\n",
        "print('10 IMUs')\n",
        "TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "            [32, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "            [64, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "            [32, 128, 4, 1, 2],   # subject 6 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "            [64, 128, 4, 1, 2],   # subject 10 left for testing\n",
        "            [32, 128, 4, 1, 2],   # subject 11 left for testing\n",
        "            [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "            [32, 128, 4, 1, 2],   # subject 15 left for testing\n",
        "            [32, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "            [128, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "            [64, 128, 4, 1, 2],   # subject 18 left for testing\n",
        "            [64, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "            [64, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "            [32, 128, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Right wrist\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [128, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [16, 128, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [16, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Chest\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [64, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [128, 128, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [64, 128, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Pelvis\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [16, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [64, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [16, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Right thigh\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [64, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [64, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [64, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Left & right thigh\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [128, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [128, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Chest & right thigh\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [128, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [128, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Right thigh & shank\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [128, 256, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [128, 256, 4, 1, 2],  # subject 17 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Right thigh & wrist\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [32, 128, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [32, 128, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [32, 128, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [32, 128, 4, 1, 2],   # subject 17 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [32, 128, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [32, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# # Right wrist & chest\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [],   # subject 2 left for testing\n",
        "#             [],   # subject 3 left for testing\n",
        "#             [],   # subject 4 left for testing\n",
        "#             [],   # subject 5 left for testing\n",
        "#             [],   # subject 6 left for testing\n",
        "#             [],   # subject 7 left for testing\n",
        "#             [],   # subject 8 left for testing\n",
        "#             [],   # subject 9 left for testing\n",
        "#             [],   # subject 10 left for testing\n",
        "#             [],   # subject 11 left for testing\n",
        "#             [],   # subject 12 left for testing\n",
        "#             [],   # subject 14 left for testing\n",
        "#             [],   # subject 15 left for testing\n",
        "#             [],   # subject 16 left for testing\n",
        "#             [],   # subject 17 left for testing\n",
        "#             [],   # subject 18 left for testing\n",
        "#             [],   # subject 19 left for testing\n",
        "#             [],   # subject 21 left for testing\n",
        "#             []]   # subject 22 left for testing\n",
        "\n",
        "# # 7 IMUs\n",
        "# TUNED_HP = [[0, 0, 0, 0, 0],      # subject 1 <--- removed due to only 5 IMUs\n",
        "#             [32, 128, 4, 1, 2],   # subject 2 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 3 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 4 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 5 left for testing\n",
        "#             [16, 256, 4, 1, 2],   # subject 6 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 7 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 8 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 9 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 10 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 11 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 12 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 14 left for testing\n",
        "#             [64, 256, 4, 1, 2],   # subject 15 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 16 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 17 left for testing\n",
        "#             [128, 256, 4, 1, 2],   # subject 18 left for testing\n",
        "#             [64, 128, 4, 1, 2],   # subject 19 left for testing\n",
        "#             [32, 256, 4, 1, 2],   # subject 21 left for testing\n",
        "#             [128, 256, 4, 1, 2]]   # subject 22 left for testing\n",
        "\n",
        "# Id for tuning parameters\n",
        "ID_BATCH_SIZE = 0\n",
        "ID_NUM_OUT = 1\n",
        "ID_KERNEL_SIZE = 2\n",
        "ID_STRIDE = 3\n",
        "ID_POOL_SIZE = 4"
      ],
      "metadata": {
        "id": "FnZ_bcwMZNuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13aea1cb-828d-4ca8-dd56-96c0a0341c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 IMUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "YYBpguracHic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing"
      ],
      "metadata": {
        "id": "rMgwuEj-cI3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all helper function here\n",
        "# helper functions\n",
        "def mkfolder(pth):\n",
        "  if not os.path.exists(pth):\n",
        "    os.mkdir(pth)\n",
        "\n",
        "def read(pth):\n",
        "  return pd.read_csv(pth)\n",
        "\n",
        "# Load and re-format the data file\n",
        "def load_df(pth):\n",
        "  dtframe = read(pth)\n",
        "  dtframe = dtframe.iloc[:, 3:] # remove the first 3 columns\n",
        "\n",
        "  # Re-formatting the column's names\n",
        "  # e.g., Pevist Accelerometer X, LeftFoot Gyroscope Z, etc.\n",
        "  names = list(dtframe.columns)\n",
        "  names = [name.split('.')[0] for name in names]\n",
        "  names_2 = dtframe.iloc[0, :]\n",
        "  names_3 = dtframe.iloc[1, :]\n",
        "\n",
        "  for i in range(len(names)):\n",
        "    names[i] = names[i]+' '+names_2[i]+' '+names_3[i]\n",
        "\n",
        "  dtframe = dtframe.iloc[2:, :] # remove the first 2 rows\n",
        "  dtframe.columns = names # update new column's names\n",
        "\n",
        "  return dtframe\n",
        "\n",
        "def slice_df(dtframe):\n",
        "  cols = sorted(dtframe.columns)\n",
        "\n",
        "  req_cols = [col for col in cols if col.split(' ')[0] in CONSIDERED_IMU_POSITION] # only keep data from considered sensors (may not be all 10), e.g., chest, pelvis, etc.\n",
        "  req_cols = [col for col in req_cols if col.split(' ')[1] not in NOT_CONSIDERED_INFO] # not use information from orientation, magnetometer or time\n",
        "\n",
        "  dtframe = dtframe.loc[:, req_cols]\n",
        "\n",
        "  return dtframe\n",
        "\n",
        "# One hot encoding\n",
        "def one_hot_encoding(label, num_clasess):\n",
        "  temp = np.zeros(num_clasess)\n",
        "  temp[label] = 1\n",
        "\n",
        "  return temp\n",
        "\n",
        "# One hot decoding\n",
        "def one_hot_decoding(num):\n",
        "  if num.shape[0] > 0:\n",
        "    temp = np.array([np.where(row == 1) for row in num])\n",
        "  else:\n",
        "    temp = np.argwhere(num == 1)\n",
        "\n",
        "  return temp\n",
        "\n",
        "# Normalize data to have the same sample length for training the network\n",
        "def normLength(arr, maxlength):\n",
        "  new_arr = np.zeros((maxlength, arr.shape[-1]))\n",
        "  for i in range(arr.shape[-1]):\n",
        "    a = arr[:, i]\n",
        "    k = a.shape[0]\n",
        "    y = np.interp(np.linspace(0, 1, maxlength), np.linspace(0, 1, k), a)\n",
        "    new_arr[:, i] = y\n",
        "  return new_arr\n",
        "\n",
        "# Obtain cluster label from the previous clustering analysis\n",
        "def get_cluster_label(ex_code):\n",
        "  cluster_found = False\n",
        "  cluster_id = 0\n",
        "\n",
        "  while not cluster_found:\n",
        "    if ex_code in CLUSTER[cluster_id]:\n",
        "      cluster_found = True\n",
        "    else:\n",
        "      cluster_id += 1 # increase the id\n",
        "\n",
        "  return cluster_id"
      ],
      "metadata": {
        "id": "DzGD7wlUcIGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset handler"
      ],
      "metadata": {
        "id": "PQE95vwtcMuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, list_of_samples, to_size, num_classes):\n",
        "      self.to_size = to_size\n",
        "\n",
        "      list_of_samples = [normLength(sample, NORM_SAMPLE_LENGTH).T for sample in list_of_samples]\n",
        "\n",
        "      self.X = [sample[:ID_EXERCISE_LABEL, :] for sample in list_of_samples] # <-- take only 60 columns of data\n",
        "      \n",
        "      if num_classes < 37:\n",
        "        self.Y = [one_hot_encoding(int(sample[ID_CLUSTER_LABEL, :][0]), num_classes) for sample in list_of_samples]\n",
        "      else:\n",
        "        self.Y = [one_hot_encoding(int(sample[ID_EXERCISE_LABEL, :][0]), num_classes) for sample in list_of_samples]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.Y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      x = torch.from_numpy(self.X[idx]).float()\n",
        "      y = self.Y[idx]\n",
        "      # y = int(self.Y[0])\n",
        "      # y = np.array(y)\n",
        "      if device == 'cuda':\n",
        "        x = x.to(device)\n",
        "        y = torch.from_numpy(y)\n",
        "        y = y.to(device)\n",
        "      return x, y"
      ],
      "metadata": {
        "id": "jyu5bLQOcOkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "qzSQJ1TjccIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Alter_Block(nn.Module):\n",
        "    def __init__(self, num_in, num_out, kernel_size, stride, pool_size, num_classes):\n",
        "        super(CNN_Alter_Block, self).__init__()\n",
        "        self.conv1    = nn.Conv1d(num_in, num_out, kernel_size, stride)      # input paramters\n",
        "        self.relu1    = nn.ReLU()\n",
        "        self.bnorm    = nn.BatchNorm1d(num_out)\n",
        "        self.pooling  = nn.MaxPool1d((pool_size))\n",
        "\n",
        "        self.flatten  = nn.Flatten()\n",
        "        self.dropout  = nn.Dropout(p = 0.5)\n",
        "        self.fcl      = nn.LazyLinear(out_features = num_classes)\n",
        "        self.sfmx     = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.cuda()\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.bnorm(x)\n",
        "        x = self.pooling(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fcl(x)\n",
        "        x = self.sfmx(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PG2gPzTMccnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate prediction"
      ],
      "metadata": {
        "id": "H64xcv_Vch9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---> Remember to check one more time before running the loop\n",
        "def predict(some_tensor, labs, num_classes):\n",
        "  some_tensor = some_tensor.cpu().detach().numpy()\n",
        "  labs        = labs.cpu().detach().numpy()\n",
        "\n",
        "  cm = np.zeros([num_classes, num_classes]) # for storing confusion matrix\n",
        "\n",
        "  y_truth = []\n",
        "  y_pred = []\n",
        "\n",
        "  count = 0 # for average accuracy\n",
        "\n",
        "  for i in range(some_tensor.shape[0]):\n",
        "    temp_pred = np.argmax(some_tensor[i])\n",
        "    temp_truth = np.argmax(labs[i])\n",
        "\n",
        "    # Update confusion matrix\n",
        "    cm[temp_truth, temp_pred] = cm[temp_truth, temp_pred] + 1\n",
        "\n",
        "    # print('Prediction = ' + str(temp_pred) + ' - ' + 'Truth = ' + str(temp_truth))\n",
        "\n",
        "    # Add truth and pred. values\n",
        "    y_truth.append(temp_truth)\n",
        "    y_pred.append(temp_pred)\n",
        "\n",
        "    # Update accuracy\n",
        "    if temp_pred == temp_truth:\n",
        "      count = count + 1\n",
        "    else:\n",
        "      pass # do nothing\n",
        "  \n",
        "  return count, cm, y_truth, y_pred"
      ],
      "metadata": {
        "id": "N733wZ0pci3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model loop"
      ],
      "metadata": {
        "id": "SyEcihkQcwAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc, best_val_loss = 0, 1.0\n",
        "\n",
        "# --- Training --- #\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, num_classes):\n",
        "    global train_mode\n",
        "    train_mode = True\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    train_loss, correct, sched_factor = 0, 0, 0\n",
        "\n",
        "    cm = np.zeros([num_classes, num_classes]) # for storing confusion matrix\n",
        "\n",
        "    y_truth = []\n",
        "    y_pred = []\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # print(X)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        # print(pred)\n",
        "        # print(predict(pred, y))\n",
        "        # print('----------------------')\n",
        "        # print(pred)\n",
        "        # print(y)\n",
        "        # break\n",
        "        y = y.type(torch.FloatTensor)\n",
        "        if device == 'cuda': y = y.cuda()\n",
        "\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        \n",
        "        temp_correct, temp_cm, temp_y_truth, temp_y_pred = predict(pred, y, num_classes)\n",
        "        correct = correct + temp_correct \n",
        "        cm = cm + temp_cm\n",
        "        y_truth = y_truth + temp_y_truth\n",
        "        y_pred = y_pred + temp_y_pred\n",
        "        train_loss  += loss_fn(pred, y).item()\n",
        "\n",
        "    train_loss /= num_batches\n",
        "    train_losses.append(train_loss)\n",
        "    correct /= size\n",
        "\n",
        "    scheduler.step(train_loss)\n",
        "\n",
        "    # print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
        "\n",
        "    return correct, cm, y_truth, y_pred\n",
        "\n",
        "# --- Testing --- #\n",
        "def test_loop(dataloader, model, loss_fn, num_classes):\n",
        "    global train_mode\n",
        "    train_mode = False\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct, size = 0, 0, 0\n",
        "\n",
        "    cm = np.zeros([num_classes, num_classes]) # for storing confusion matrix\n",
        "\n",
        "    y_truth = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            # pred = predict(pred, y)\n",
        "            y = y.type(torch.FloatTensor)\n",
        "            if device == 'cuda': y = y.cuda()\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item() # comment out\n",
        "\n",
        "            temp_correct, temp_cm, temp_y_truth, temp_y_pred = predict(pred, y, num_classes)\n",
        "            correct = correct + temp_correct\n",
        "            cm = cm + temp_cm\n",
        "            y_truth = y_truth + temp_y_truth\n",
        "            y_pred = y_pred + temp_y_pred\n",
        "            size    += y.shape[0]\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "    return correct, cm, y_truth, y_pred"
      ],
      "metadata": {
        "id": "A9MzFkEzcw2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSOCV"
      ],
      "metadata": {
        "id": "Wkj8bSKqcyWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def losocv_split_train_list(all_subject_id, test_subject):  \n",
        "  train_list = [m for m in all_subject_id if m != test_subject]\n",
        "\n",
        "  return train_list"
      ],
      "metadata": {
        "id": "vKrPN1c2czIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Subjects and exercises"
      ],
      "metadata": {
        "id": "GxgrBf1Uc0ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = 'drive/MyDrive/mbl/parsed_h5_csv/'\n",
        "subs = sorted(list(os.listdir(root_path)))\n",
        "# subs = subs[:-1] # remove 'merged' # we don't have 'merged' in this folder"
      ],
      "metadata": {
        "id": "C2Nyez44c2WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subs"
      ],
      "metadata": {
        "id": "oNaVSHaOc7AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292b0a19-429d-45e8-d4e8-a8781d606b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SUB01',\n",
              " 'SUB02',\n",
              " 'SUB03',\n",
              " 'SUB04',\n",
              " 'SUB05',\n",
              " 'SUB06',\n",
              " 'SUB07',\n",
              " 'SUB08',\n",
              " 'SUB09',\n",
              " 'SUB10',\n",
              " 'SUB11',\n",
              " 'SUB12',\n",
              " 'SUB14',\n",
              " 'SUB15',\n",
              " 'SUB16',\n",
              " 'SUB17',\n",
              " 'SUB18',\n",
              " 'SUB19',\n",
              " 'SUB21',\n",
              " 'SUB22']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total should be 20\n",
        "num_subject = len(subs)\n",
        "num_subject"
      ],
      "metadata": {
        "id": "WW0gL7ysc8C0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e41798-6874-462f-942d-b1832711164e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain exercises"
      ],
      "metadata": {
        "id": "NqT41Sxxc9rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exercises = [sorted(os.listdir(root_path+sub)) for sub in subs]\n",
        "\n",
        "# Get types of exercises (i.e., physical activities)\n",
        "exercise_types = []\n",
        "for ex in exercises:\n",
        "  exercise_types.extend(ex)"
      ],
      "metadata": {
        "id": "QSiF9m2Cc-qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ex in exercises:\n",
        "  print(len(ex), ex)"
      ],
      "metadata": {
        "id": "Mf6pYUy9dBIt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6157c2-697c-48bf-b4ef-da08a2115565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 ['CMJDL', 'DropJumpDL', 'DropLandDL', 'HeelRaise', 'Lunge', 'MaxJump', 'Run', 'SqDL', 'SqHalfDL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "36 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "36 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "34 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "36 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "36 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "36 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n",
            "37 ['BulgSq', 'CMJDL', 'CMJSL', 'DeclineSq', 'DropJumpDL', 'DropJumpSL', 'DropLandDL', 'DropLandSL', 'FwHop', 'FwHopFast', 'FwJump', 'FwJumpFast', 'HeelRaise', 'LatHop', 'LatHopFast', 'LatJump', 'LatJumpFast', 'Lunge', 'MaxHop', 'MaxJump', 'Pose', 'Run', 'RunCut', 'RunDec', 'SpainSq', 'SplitJump', 'SportJump', 'SqDL', 'SqHalfDL', 'SqHalfSL', 'SqSL', 'StepDnH', 'StepDnL', 'StepUpH', 'StepUpL', 'SumoSq', 'Walk']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exercise_types = np.array(exercise_types)\n",
        "exercise_types, _ = np.unique(exercise_types, return_index=True)\n",
        "exercise_types = exercise_types.tolist()\n",
        "exercise_types"
      ],
      "metadata": {
        "id": "iDZWBX5CdDBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a467c2-c805-48c8-aafc-5a6c12b2c2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BulgSq',\n",
              " 'CMJDL',\n",
              " 'CMJSL',\n",
              " 'DeclineSq',\n",
              " 'DropJumpDL',\n",
              " 'DropJumpSL',\n",
              " 'DropLandDL',\n",
              " 'DropLandSL',\n",
              " 'FwHop',\n",
              " 'FwHopFast',\n",
              " 'FwJump',\n",
              " 'FwJumpFast',\n",
              " 'HeelRaise',\n",
              " 'LatHop',\n",
              " 'LatHopFast',\n",
              " 'LatJump',\n",
              " 'LatJumpFast',\n",
              " 'Lunge',\n",
              " 'MaxHop',\n",
              " 'MaxJump',\n",
              " 'Pose',\n",
              " 'Run',\n",
              " 'RunCut',\n",
              " 'RunDec',\n",
              " 'SpainSq',\n",
              " 'SplitJump',\n",
              " 'SportJump',\n",
              " 'SqDL',\n",
              " 'SqHalfDL',\n",
              " 'SqHalfSL',\n",
              " 'SqSL',\n",
              " 'StepDnH',\n",
              " 'StepDnL',\n",
              " 'StepUpH',\n",
              " 'StepUpL',\n",
              " 'SumoSq',\n",
              " 'Walk']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total should be 37\n",
        "num_exercise = len(exercise_types)\n",
        "num_exercise"
      ],
      "metadata": {
        "id": "XXU3KSkSdETD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84dc1562-a489-46e8-9502-630512489f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label clusters"
      ],
      "metadata": {
        "id": "l3u4nr103J3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_clusters = len(CLUSTER)\n",
        "num_clusters"
      ],
      "metadata": {
        "id": "hh_vWXMO3MJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a55c541-fc17-4cf6-e462-8eb9b31cca15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label exercises"
      ],
      "metadata": {
        "id": "c8zB3jgAdGWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exercise_code = list(range(0, num_exercise))\n",
        "label_code = dict(zip(exercise_types, exercise_code))\n",
        "code_label = dict(zip(exercise_code, exercise_types))"
      ],
      "metadata": {
        "id": "pHVOi1qRdFpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_code"
      ],
      "metadata": {
        "id": "8E3O7JHQdISV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb376d6-60a8-428e-9ab1-9885182214f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BulgSq': 0,\n",
              " 'CMJDL': 1,\n",
              " 'CMJSL': 2,\n",
              " 'DeclineSq': 3,\n",
              " 'DropJumpDL': 4,\n",
              " 'DropJumpSL': 5,\n",
              " 'DropLandDL': 6,\n",
              " 'DropLandSL': 7,\n",
              " 'FwHop': 8,\n",
              " 'FwHopFast': 9,\n",
              " 'FwJump': 10,\n",
              " 'FwJumpFast': 11,\n",
              " 'HeelRaise': 12,\n",
              " 'LatHop': 13,\n",
              " 'LatHopFast': 14,\n",
              " 'LatJump': 15,\n",
              " 'LatJumpFast': 16,\n",
              " 'Lunge': 17,\n",
              " 'MaxHop': 18,\n",
              " 'MaxJump': 19,\n",
              " 'Pose': 20,\n",
              " 'Run': 21,\n",
              " 'RunCut': 22,\n",
              " 'RunDec': 23,\n",
              " 'SpainSq': 24,\n",
              " 'SplitJump': 25,\n",
              " 'SportJump': 26,\n",
              " 'SqDL': 27,\n",
              " 'SqHalfDL': 28,\n",
              " 'SqHalfSL': 29,\n",
              " 'SqSL': 30,\n",
              " 'StepDnH': 31,\n",
              " 'StepDnL': 32,\n",
              " 'StepUpH': 33,\n",
              " 'StepUpL': 34,\n",
              " 'SumoSq': 35,\n",
              " 'Walk': 36}"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_label"
      ],
      "metadata": {
        "id": "M0AGuRDWdJPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d791c86-aa3c-4009-9e4b-dae56c5a47e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'BulgSq',\n",
              " 1: 'CMJDL',\n",
              " 2: 'CMJSL',\n",
              " 3: 'DeclineSq',\n",
              " 4: 'DropJumpDL',\n",
              " 5: 'DropJumpSL',\n",
              " 6: 'DropLandDL',\n",
              " 7: 'DropLandSL',\n",
              " 8: 'FwHop',\n",
              " 9: 'FwHopFast',\n",
              " 10: 'FwJump',\n",
              " 11: 'FwJumpFast',\n",
              " 12: 'HeelRaise',\n",
              " 13: 'LatHop',\n",
              " 14: 'LatHopFast',\n",
              " 15: 'LatJump',\n",
              " 16: 'LatJumpFast',\n",
              " 17: 'Lunge',\n",
              " 18: 'MaxHop',\n",
              " 19: 'MaxJump',\n",
              " 20: 'Pose',\n",
              " 21: 'Run',\n",
              " 22: 'RunCut',\n",
              " 23: 'RunDec',\n",
              " 24: 'SpainSq',\n",
              " 25: 'SplitJump',\n",
              " 26: 'SportJump',\n",
              " 27: 'SqDL',\n",
              " 28: 'SqHalfDL',\n",
              " 29: 'SqHalfSL',\n",
              " 30: 'SqSL',\n",
              " 31: 'StepDnH',\n",
              " 32: 'StepDnL',\n",
              " 33: 'StepUpH',\n",
              " 34: 'StepUpL',\n",
              " 35: 'SumoSq',\n",
              " 36: 'Walk'}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label subjects"
      ],
      "metadata": {
        "id": "lMOehxgZdLR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subs_code = list(range(0, num_subject))\n",
        "subject_code = dict(zip(subs, subs_code))\n",
        "code_subject = dict(zip(subs_code, subs))"
      ],
      "metadata": {
        "id": "P0HAUnbsdMCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subject_code"
      ],
      "metadata": {
        "id": "AwmnYCRudN_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf428f0a-b640-44b8-f4cc-87b0ce8c6fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'SUB01': 0,\n",
              " 'SUB02': 1,\n",
              " 'SUB03': 2,\n",
              " 'SUB04': 3,\n",
              " 'SUB05': 4,\n",
              " 'SUB06': 5,\n",
              " 'SUB07': 6,\n",
              " 'SUB08': 7,\n",
              " 'SUB09': 8,\n",
              " 'SUB10': 9,\n",
              " 'SUB11': 10,\n",
              " 'SUB12': 11,\n",
              " 'SUB14': 12,\n",
              " 'SUB15': 13,\n",
              " 'SUB16': 14,\n",
              " 'SUB17': 15,\n",
              " 'SUB18': 16,\n",
              " 'SUB19': 17,\n",
              " 'SUB21': 18,\n",
              " 'SUB22': 19}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_subject"
      ],
      "metadata": {
        "id": "JoeCYVaQdOI1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17ae00c2-6f01-432f-d26d-f452443cc2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'SUB01',\n",
              " 1: 'SUB02',\n",
              " 2: 'SUB03',\n",
              " 3: 'SUB04',\n",
              " 4: 'SUB05',\n",
              " 5: 'SUB06',\n",
              " 6: 'SUB07',\n",
              " 7: 'SUB08',\n",
              " 8: 'SUB09',\n",
              " 9: 'SUB10',\n",
              " 10: 'SUB11',\n",
              " 11: 'SUB12',\n",
              " 12: 'SUB14',\n",
              " 13: 'SUB15',\n",
              " 14: 'SUB16',\n",
              " 15: 'SUB17',\n",
              " 16: 'SUB18',\n",
              " 17: 'SUB19',\n",
              " 18: 'SUB21',\n",
              " 19: 'SUB22'}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collect Data Samples"
      ],
      "metadata": {
        "id": "zvQVptDu1JlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_list, file_paths = [], []\n",
        "\n",
        "num_missing_dt = 0 # count number of files with missing data to remove them out\n",
        "num_imu = len(CONSIDERED_IMU_POSITION)\n",
        "num_col_in_dt = num_imu*NUM_SENSOR_INFO*NUM_AX_PER_SENSOR + 3 # exercise label + cluster label + subject label\n",
        "\n",
        "print(\"Number of columns that should be in the dataframe = \" + str(num_col_in_dt))\n",
        "\n",
        "no_of_samples = None\n",
        "\n",
        "# Loop through subjects (removed the first subject due to only 5 IMUs)\n",
        "for subject in tqdm(subs[1:]): \n",
        "  print()\n",
        "  print('Collecting data from subject ' + str(subject) + ' ...')\n",
        "\n",
        "  for ex in exercise_types:\n",
        "    # If the subject perform the task\n",
        "    try:\n",
        "      folder_path = root_path + subject + '/' + ex + '/'\n",
        "      file_names = os.listdir(folder_path) # obtain all parsed data files\n",
        "      no_of_samples = len(file_names) # to display the no. of samples lately\n",
        "\n",
        "      for file_name in file_names:\n",
        "        sample_path = folder_path + file_name\n",
        "        df = load_df(sample_path) # load and re-format the data file\n",
        "        df = slice_df(df) # pick data from considered sensors and remove unnecessary information\n",
        "        df['target'] = label_code[ex] # add output for the data file (i.e., exercise label)\n",
        "        df['cluster'] = get_cluster_label(label_code[ex]) # i.e., cluster label\n",
        "        df['subject_id'] = subject_code[subject] # add subject id for the data (i.e., subject label)\n",
        "\n",
        "        sample_arr = np.array(df).astype(float) # convert to numpy array type\n",
        "\n",
        "        # Check if the data has all considered parts\n",
        "        if sample_arr.shape[1] != num_col_in_dt:\n",
        "          num_missing_dt += 1\n",
        "        else:\n",
        "          sample_list.append(sample_arr)\n",
        "\n",
        "        # break\n",
        "      # print('\\n' + str(no_of_samples) + ' samples collected from ' + ex)\n",
        "      \n",
        "    except:\n",
        "      # print('\\n' + ex + ' was missing')\n",
        "      pass # do nothing\n",
        "\n",
        "  print() # TBD"
      ],
      "metadata": {
        "id": "SqBpc_si1HkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2c9362-3e31-4e91-91ce-b7288051cf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns that should be in the dataframe = 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting data from subject SUB02 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/19 [00:02<00:51,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB03 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 2/19 [00:06<00:52,  3.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB04 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 3/19 [00:09<00:50,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB05 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 4/19 [00:12<00:46,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB06 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 5/19 [00:15<00:42,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB07 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 6/19 [00:18<00:40,  3.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB08 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 7/19 [00:21<00:37,  3.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB09 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 8/19 [00:24<00:34,  3.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB10 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 9/19 [00:27<00:31,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB11 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 10/19 [00:30<00:27,  3.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB12 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 11/19 [00:33<00:24,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB14 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 12/19 [00:37<00:21,  3.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB15 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 13/19 [00:40<00:18,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB16 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 14/19 [00:43<00:15,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB17 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 15/19 [00:46<00:12,  3.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB18 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 16/19 [00:50<00:10,  3.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB19 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 17/19 [00:53<00:06,  3.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB21 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▍| 18/19 [00:58<00:03,  3.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Collecting data from subject SUB22 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19/19 [01:01<00:00,  3.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sample_list)"
      ],
      "metadata": {
        "id": "1no_7ktU1L5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d243af8f-b806-4820-de75-339b87dd6781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3212"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Loop"
      ],
      "metadata": {
        "id": "vlFvieEGdqj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check device"
      ],
      "metadata": {
        "id": "9DSQa-Avdt5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "O_FWvzYMdsEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f035775b-b6dc-4785-e4df-678c05dd890f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [train_subjects for train_subjects in all_subject_id if train_subjects != test_subject]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM6Vy_LaYZPa",
        "outputId": "c26f3096-2d69-4c31-942a-b58bf0ee6c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance evaluation *(with tuned hyper-parameters recorded from the tuning)*"
      ],
      "metadata": {
        "id": "oAVyNY70d2gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed subject 1 due to missing IMUs\n",
        "# all_subject_id = list(range(1, NUM_SUBJECT))\n",
        "all_subject_id = list(range(1, 19))\n",
        "\n",
        "# Training/testing accuracy of performance evaluation\n",
        "perf_train_acc = []\n",
        "perf_test_acc = []\n",
        "\n",
        "# Training/testing confusion matrices\n",
        "perf_train_cm = []\n",
        "perf_test_cm = []\n",
        "\n",
        "# Testing prediction performance\n",
        "perf_test_y_pred = []\n",
        "perf_test_y_truth = []\n",
        "\n",
        "# Performance evaluation\n",
        "# for test_subject in all_subject_id[0:1]: # for testing purpose\n",
        "for test_subject in all_subject_id[:]:\n",
        "  print('# Working on test subject ' + str(test_subject))\n",
        "\n",
        "  # --- Divide training/testing data according to LOSOCV --- #\n",
        "  train_list, test_list = [], []\n",
        "\n",
        "  # # UNCOMMENT THIS ONCE FINISHING TESTING \n",
        "  # for sample in sample_list:    \n",
        "  #   if sample[0, ID_SUBJECT_LABEL] != test_subject: # data not from the testing subject\n",
        "  #     train_list.append(sample) \n",
        "  #   else: # data from the testing subject\n",
        "  #     test_list.append(sample)  \n",
        "\n",
        "  for sample in sample_list:    \n",
        "    if sample[0, ID_SUBJECT_LABEL] in [train_subject for train_subject in all_subject_id if train_subject != test_subject]:\n",
        "      train_list.append(sample) \n",
        "    elif sample[0, ID_SUBJECT_LABEL] == test_subject:\n",
        "      test_list.append(sample)  \n",
        "    else: \n",
        "      pass\n",
        "  \n",
        "  print('* training size: ' + str(len(train_list)))\n",
        "  print('* testing size: ' + str(len(test_list)))\n",
        "\n",
        "  # --- Obtain hyper-parameters from the pre-tuning process --- #\n",
        "  print('--- Obtain hyper-parameters')\n",
        "  hp_point = TUNED_HP[test_subject] # get the set of tune hyper-parameters\n",
        "  s_batch_size  = hp_point[ID_BATCH_SIZE]\n",
        "  s_num_out     = hp_point[ID_NUM_OUT]\n",
        "  s_kernel_size = hp_point[ID_KERNEL_SIZE]\n",
        "  s_stride      = hp_point[ID_STRIDE] \n",
        "  s_pool_size   = hp_point[ID_POOL_SIZE]\n",
        "\n",
        "  print(' + batch size = ' + str(s_batch_size))\n",
        "  print(' + conv. num. out = ' + str(s_num_out))\n",
        "  print(' + kernel size = ' + str(s_kernel_size))\n",
        "  print(' + stride length = ' + str(s_stride))\n",
        "  print(' + pool size = ' + str(s_pool_size))\n",
        "\n",
        "  # --- Make dataset --- #\n",
        "  # Normalize\n",
        "  train_data  = MyDataset(train_list, NORM_SAMPLE_LENGTH, num_clusters) # <-- Here to modify the number of classes (i.e., num_clusters or num_exercise)\n",
        "  test_data   = MyDataset(test_list, NORM_SAMPLE_LENGTH, num_clusters) # <-- Here to modify the number of classes (i.e., num_clusters or num_exercise)\n",
        "\n",
        "  # Wrap dataloader   \n",
        "  train_dataloader  = DataLoader(train_data, batch_size = s_batch_size, shuffle=True)\n",
        "  test_dataloader   = DataLoader(test_data, batch_size  = s_batch_size, shuffle=False)\n",
        "\n",
        "  # --- Model and training --- #\n",
        "  # Model\n",
        "  # model = CNN_One_Block(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  # model = CNN_Two_Blocks(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  # model = CNN_Three_Blocks(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  # model = CNN_One_Deep_Block(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  # model = CNN_Two_Deep_Blocks(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  # model = CNN_Parallel_Blocks(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size)\n",
        "  model = CNN_Alter_Block(conv_num_in, s_num_out, s_kernel_size, s_stride, s_pool_size, num_clusters) # <-- Here to modify the number of classes (i.e., num_clusters or num_exercise)\n",
        "  if device == 'cuda': model = model.cuda()\n",
        "\n",
        "  # for plotting\n",
        "  train_losses, val_losses = [], []\n",
        "\n",
        "  # Initialize the loss function\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Initialize the optimisation function\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = ADAM_WEIGHT_DECAY)\n",
        "\n",
        "  # Scheduler\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = LEARNING_RATE_REDUCTION_FACTOR)\n",
        "\n",
        "  print('--- Start the performance evaluation')\n",
        "  for t in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    temp_train_acc, temp_train_cm, _, _  = train_loop(train_dataloader, model, loss_fn, optimizer, num_clusters) # <-- Here to modify the number of classes (i.e., num_clusters or num_exercise)\n",
        "    temp_test_acc, temp_test_cm, temp_y_truth, temp_y_pred   = test_loop(test_dataloader, model, loss_fn, num_clusters) # <-- Here to modify the number of classes (i.e., num_clusters or num_exercise)\n",
        "\n",
        "  # Store the training/testing performance\n",
        "  print('*** Training/testing performance')\n",
        "  perf_train_acc.append(temp_train_acc)\n",
        "  perf_test_acc.append(temp_test_acc)\n",
        "  print(perf_train_acc)\n",
        "  print(perf_test_acc)\n",
        "\n",
        "  # Store the confusion matrices\n",
        "  print('*** Confusion matrix')  \n",
        "  perf_train_cm.append(temp_train_cm)\n",
        "  perf_test_cm.append(temp_test_cm)\n",
        "  print('Not displayed but added')\n",
        "  # print(perf_train_cm)\n",
        "  # print(perf_test_cm)\n",
        "\n",
        "  perf_test_y_truth.append(temp_y_truth)\n",
        "  perf_test_y_pred.append(temp_y_pred)\n"
      ],
      "metadata": {
        "id": "inN796vqd82j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa658fb5-9d0f-4b2b-aec2-6f8f2b189b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Working on test subject 1\n",
            "* training size: 2886\n",
            "* testing size: 148\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997]\n",
            "[0.9864864864864865]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 2\n",
            "* training size: 2870\n",
            "* testing size: 164\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509]\n",
            "[0.9864864864864865, 0.9146341463414634]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 3\n",
            "* training size: 2870\n",
            "* testing size: 164\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 4\n",
            "* training size: 2877\n",
            "* testing size: 157\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 5\n",
            "* training size: 2869\n",
            "* testing size: 165\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 128\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 6\n",
            "* training size: 2868\n",
            "* testing size: 166\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 7\n",
            "* training size: 2865\n",
            "* testing size: 169\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 8\n",
            "* training size: 2878\n",
            "* testing size: 156\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 9\n",
            "* training size: 2880\n",
            "* testing size: 154\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 128\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 10\n",
            "* training size: 2868\n",
            "* testing size: 166\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 128\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 11\n",
            "* training size: 2874\n",
            "* testing size: 160\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 12\n",
            "* training size: 2866\n",
            "* testing size: 168\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 13\n",
            "* training size: 2863\n",
            "* testing size: 171\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 128\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 14\n",
            "* training size: 2873\n",
            "* testing size: 161\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 32\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515, 0.9937888198757764]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 15\n",
            "* training size: 2842\n",
            "* testing size: 192\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 128\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342, 1.0, 0.9996481351161154]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515, 0.9937888198757764, 0.9583333333333334]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 16\n",
            "* training size: 2831\n",
            "* testing size: 203\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 128\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342, 1.0, 0.9996481351161154, 0.9996467679265277]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515, 0.9937888198757764, 0.9583333333333334, 0.9802955665024631]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 17\n",
            "* training size: 2850\n",
            "* testing size: 184\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342, 1.0, 0.9996481351161154, 0.9996467679265277, 1.0]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515, 0.9937888198757764, 0.9583333333333334, 0.9802955665024631, 1.0]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n",
            "# Working on test subject 18\n",
            "* training size: 2848\n",
            "* testing size: 186\n",
            "--- Obtain hyper-parameters\n",
            " + batch size = 64\n",
            " + conv. num. out = 256\n",
            " + kernel size = 4\n",
            " + stride length = 1\n",
            " + pool size = 2\n",
            "--- Start the performance evaluation\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "*** Training/testing performance\n",
            "[0.9996534996534997, 0.9996515679442509, 1.0, 1.0, 0.9996514464970373, 1.0, 1.0, 0.9996525364836693, 0.9996527777777777, 1.0, 1.0, 1.0, 0.9996507160321342, 1.0, 0.9996481351161154, 0.9996467679265277, 1.0, 0.9996488764044944]\n",
            "[0.9864864864864865, 0.9146341463414634, 0.9695121951219512, 0.9808917197452229, 0.8303030303030303, 0.9879518072289156, 0.9881656804733728, 0.9294871794871795, 0.9545454545454546, 0.8012048192771084, 1.0, 0.9404761904761905, 0.9883040935672515, 0.9937888198757764, 0.9583333333333334, 0.9802955665024631, 1.0, 0.9946236559139785]\n",
            "*** Confusion matrix\n",
            "Not displayed but added\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monitor the performance"
      ],
      "metadata": {
        "id": "VvqjEi3Y2kX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the average training/testing accuracy\n",
        "avg_train_acc = round((sum(perf_train_acc)*100.0/len(perf_train_acc)), 4)\n",
        "avg_test_acc = round((sum(perf_test_acc)*100.0/len(perf_test_acc)), 4)\n",
        "\n",
        "print('Average training accuracy = ' + str(avg_train_acc))\n",
        "print('Average testing accuracy = ' + str(avg_test_acc))"
      ],
      "metadata": {
        "id": "KcHvtdY6yZD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acbef06-9939-42ee-add4-092ef2a95dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training accuracy = 99.9825\n",
            "Average testing accuracy = 95.55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrices\n",
        "import seaborn as sns \n",
        "\n",
        "verf_count = 0\n",
        "\n",
        "for i in range(len(perf_test_cm)):\n",
        "  # plt.figure(i)\n",
        "  # sns.heatmap(perf_test_cm[i], cmap = 'YlGnBu')\n",
        "  # plt.title('No. samples = ' + str(np.sum(perf_test_cm[i])) + '\\n' + '(Testing) accuracy = ' + str(perf_test_acc[i]))\n",
        "  # plt.xlabel('Prediction')\n",
        "  # plt.ylabel('Truth')\n",
        "\n",
        "  verf_count = verf_count + np.sum(perf_test_cm[i])\n",
        "\n",
        "print('Would be wrong if verf_count is not the total number of samples in the dataset, i.e., 3212')\n",
        "print(verf_count)"
      ],
      "metadata": {
        "id": "DpbOHqwe2YKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb984b56-d069-4710-f171-062b3bead338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Would be wrong if verf_count is not the total number of samples in the dataset, i.e., 3212\n",
            "3034.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store results for later processing"
      ],
      "metadata": {
        "id": "TP_clheJ9XY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store accuracy\n",
        "with open('train_acc.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_train_acc))\n",
        "with open('test_acc.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_test_acc))\n",
        "\n",
        "# Store confusion matrices\n",
        "with open('train_cm.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_train_cm))\n",
        "with open('test_cm.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_test_cm))\n",
        "\n",
        "# Store truth and pred values of the testing set\n",
        "with open('test_y_truth.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_test_y_truth))\n",
        "with open('test_y_pred.npy', 'wb') as f:\n",
        "  np.save(f, np.array(perf_test_y_pred))"
      ],
      "metadata": {
        "id": "pyFFJ81J4JB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771e937e-311e-4a54-a2c3-d1441d71b29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Post-processing Results"
      ],
      "metadata": {
        "id": "AQCHQeHv98r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "4F6ee_IYfqnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data"
      ],
      "metadata": {
        "id": "-TVmepMp9_rb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve accuracy\n",
        "with open('train_acc.npy', 'rb') as f:\n",
        "  r_train_acc = np.load(f)\n",
        "with open('test_acc.npy', 'rb') as f:\n",
        "  r_test_acc = np.load(f)\n",
        "\n",
        "# Retrieve confusion matrices\n",
        "with open('train_cm.npy', 'rb') as f:\n",
        "  r_train_cm = np.load(f)\n",
        "with open('test_cm.npy', 'rb') as f:\n",
        "  r_test_cm = np.load(f)\n",
        "\n",
        "# Retrieve y truth and pred\n",
        "with open('test_y_truth.npy', 'rb') as f:\n",
        "  r_y_truth = np.load(f, allow_pickle = True)\n",
        "with open('test_y_pred.npy', 'rb') as f:\n",
        "  r_y_pred = np.load(f, allow_pickle = True)"
      ],
      "metadata": {
        "id": "Yraaa-t24-Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(perf_test_y_truth[0])"
      ],
      "metadata": {
        "id": "YBxxHkP6vIWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c398baf9-1ed5-4a4e-84d6-d25e31b5f3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "metadata": {},
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure\n",
        "sns.heatmap(r_test_cm[9], cmap = 'YlGnBu')\n",
        "print(np.sum(r_test_cm[0]))"
      ],
      "metadata": {
        "id": "F7tRvPvk-0mC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "d27ade95-588b-4323-fbc0-0491347fe6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-342-a6310a4c1d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_test_cm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'YlGnBu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_test_cm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 9"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_train_cm[0][1, :].shape"
      ],
      "metadata": {
        "id": "xlNJbfU55dFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d061127-467c-433b-ce13-1a11f5b63db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37,)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_test_cm.shape"
      ],
      "metadata": {
        "id": "ZPKJ72qz91tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a8195e-9908-4ef4-cdd5-fef18ca62aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 37, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize confusion matrix\n",
        "def normalize_cm(cm):\n",
        "  norm_cm = np.zeros(cm.shape) # init\n",
        "\n",
        "  num_sbj = cm.shape[0]\n",
        "  num_ex = cm.shape[1]\n",
        "\n",
        "  # Loop through subject with different confusion matrices\n",
        "  for s in range(num_sbj):\n",
        "\n",
        "    # Loop through exercises\n",
        "    for e in range(num_ex):\n",
        "\n",
        "      # Check if there is missing exercise\n",
        "      num_trial = sum(cm[s][e, :])\n",
        "\n",
        "      if num_trial != 0:\n",
        "        norm_cm[s][e, :] = cm[s][e, :]/num_trial\n",
        "      else:\n",
        "        pass # do nothing since the row is already zero\n",
        "\n",
        "  return norm_cm\n",
        "\n",
        "# Average the normalize confusion matrix\n",
        "def get_avg_cm(norm_cm):\n",
        "  num_sbj = norm_cm.shape[0]\n",
        "  num_ex = norm_cm.shape[1]\n",
        "\n",
        "  avg_norm_cm = np.zeros([num_ex, num_ex]) # init\n",
        "  num_trials = np.zeros(num_ex) # store the no. of trials for each exercise\n",
        "\n",
        "  # Loop through subjects\n",
        "  for s in range(num_sbj):\n",
        "     \n",
        "     # Loop through exercises\n",
        "     for e in range(num_ex):\n",
        "\n",
        "      # Check if there is missing trial\n",
        "      if sum(norm_cm[s][e, :]) != 0:\n",
        "        avg_norm_cm[e, :] = avg_norm_cm[e, :] + norm_cm[s][e, :]\n",
        "        num_trials[e] = num_trials[e] + 1\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  # Compute the average\n",
        "  for e in range(num_ex):\n",
        "    avg_norm_cm[e, :] = avg_norm_cm[e, :]/num_trials[e]\n",
        "\n",
        "  return avg_norm_cm\n",
        "\n",
        "# Get precision, recall, and F1-score (averaged across exercises and subjects) from confusion matrices\n",
        "def get_avg_metrics_from_cm(cm):\n",
        "  precision_mat = np.zeros([19, 37]) # each row is a subject, each column is an exercise\n",
        "  recall_mat = np.zeros([19, 37])\n",
        "  f1_score_mat = np.zeros([19, 37])\n",
        "\n",
        "  num_sbj = cm.shape[0]\n",
        "  num_ex = cm.shape[1]\n",
        "\n",
        "  for s in range(num_sbj):\n",
        "\n",
        "    for e in range(num_ex):\n",
        "      \n",
        "      # Compute precision\n",
        "      if sum(cm[s][:, e]) != 0:\n",
        "        temp_precision = cm[s][e, e] / sum(cm[s][:, e])        \n",
        "      else:\n",
        "        temp_precision = 0\n",
        "      precision_mat[s, e] = temp_precision\n",
        "\n",
        "      # Compute recall\n",
        "      if sum(cm[s][e, :]) != 0:\n",
        "        temp_recall = cm[s][e, e] / sum(cm[s][e, :])\n",
        "      else:\n",
        "        temp_recall = 0\n",
        "      recall_mat[s, e] = temp_recall\n",
        "\n",
        "      # Compute F1-score\n",
        "      if (temp_precision != 0) and (temp_recall != 0):\n",
        "        temp_f1 = 2*(temp_recall*temp_precision)/(temp_recall + temp_precision)\n",
        "      else:\n",
        "        temp_f1 = 0\n",
        "      f1_score_mat[s, e] = temp_f1\n",
        "  \n",
        "  # Average\n",
        "  precision = precision_mat.mean()\n",
        "  recall = recall_mat.mean()\n",
        "  f1 = f1_score_mat.mean()\n",
        "\n",
        "  return precision, recall, f1"
      ],
      "metadata": {
        "id": "BgwWfQCa5mMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_train_cm = normalize_cm(r_train_cm)\n",
        "norm_test_cm = normalize_cm(r_test_cm)"
      ],
      "metadata": {
        "id": "dpNAsqbt_O5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbj_list = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22]\n",
        "\n",
        "for i in range(len(r_test_cm)):\n",
        "  plt.figure(i)\n",
        "  sns.heatmap(r_test_cm[i], cmap = 'YlGnBu')\n",
        "  plt.title('S' + str(sbj_list[i]) + ' left for testing')\n",
        "  plt.xlabel('Prediction')\n",
        "  plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "yUjT6QQ_4Xvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sbj_list = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22]\n",
        "\n",
        "for i in range(len(norm_test_cm)):\n",
        "  plt.figure(i)\n",
        "  sns.heatmap(norm_test_cm[i], cmap = 'YlGnBu')\n",
        "  plt.title('S' + str(sbj_list[i]) + ' left for testing')\n",
        "  plt.xlabel('Prediction')\n",
        "  plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "4AryxmKY_aM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_norm_cm = get_avg_cm(norm_test_cm)"
      ],
      "metadata": {
        "id": "DwH6yGTU_gZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(avg_norm_cm, cmap = 'YlGnBu', vmin = 0, vmax = 1)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "N7RnxFWwJ8Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(r_train_acc)"
      ],
      "metadata": {
        "id": "DNGtzzpiKDZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(r_test_acc)"
      ],
      "metadata": {
        "id": "wxV6sxqwGE8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "outputId": "1501a23d-112e-4853-e874-fe5858a15acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0\n",
              "0   0.986486\n",
              "1   0.914634\n",
              "2   0.969512\n",
              "3   0.980892\n",
              "4   0.830303\n",
              "5   0.987952\n",
              "6   0.988166\n",
              "7   0.929487\n",
              "8   0.954545\n",
              "9   0.801205\n",
              "10  1.000000\n",
              "11  0.940476\n",
              "12  0.988304\n",
              "13  0.993789\n",
              "14  0.958333\n",
              "15  0.980296\n",
              "16  1.000000\n",
              "17  0.994624"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f95e2596-e27e-45b0-a4c6-e875d0fc4fa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.986486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.914634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.969512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.980892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.830303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.987952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.988166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.929487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.954545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.801205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.940476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.988304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.993789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.958333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.980296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.994624</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95e2596-e27e-45b0-a4c6-e875d0fc4fa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f95e2596-e27e-45b0-a4c6-e875d0fc4fa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f95e2596-e27e-45b0-a4c6-e875d0fc4fa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get precision, recall, and F1-score"
      ],
      "metadata": {
        "id": "MoX8CVdmDjyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Ecmmm382IgS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision\n",
        "precision_arr = []\n",
        "for i in range(19):\n",
        "  precision_arr.append(precision_score(r_y_truth[i], r_y_pred[i], average = 'macro'))\n",
        "\n",
        "pd.DataFrame(precision_arr)"
      ],
      "metadata": {
        "id": "2aqFl9r4xhuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall\n",
        "recall_arr = []\n",
        "for i in range(19):\n",
        "  recall_arr.append(recall_score(r_y_truth[i], r_y_pred[i], average = 'macro'))\n",
        "\n",
        "pd.DataFrame(recall_arr)"
      ],
      "metadata": {
        "id": "8LhNDyEfx5Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score\n",
        "f1_arr = []\n",
        "\n",
        "for i in range(19):\n",
        "  f1_arr.append(f1_score(r_y_truth[i], r_y_pred[i], average = 'macro'))\n",
        "\n",
        "pd.DataFrame(f1_arr)"
      ],
      "metadata": {
        "id": "Mxg4F-TJyxQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "eX-AcBWSVU9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_dist = np.zeros(len(CLUSTER))\n",
        "\n",
        "for i in range(len(sample_list)):\n",
        "  temp_id = int(sample_list[i][0, ID_CLUSTER_LABEL])\n",
        "  cluster_dist[temp_id] += 1"
      ],
      "metadata": {
        "id": "Y-C-OGIFVWgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdbXw-MQXaeV",
        "outputId": "f8274137-040a-4e4e-8b0e-d9647b3090a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([816., 540., 646.,  59., 255.,  86., 232., 335., 122., 121.])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10, 8))\n",
        "plt.bar(list(range(10)), cluster_dist)\n",
        "plt.hlines(min(cluster_dist), -1, 10, linestyles = 'dashed', colors = 'k')\n",
        "plt.hlines(max(cluster_dist), -1, 10, linestyles = 'dashed', colors = 'r')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.xlim([-1, 10])"
      ],
      "metadata": {
        "id": "uxcCVD7SxMVY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "1fe1537c-214f-4a74-c78b-1ea35def4a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.0, 10.0)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mVguJE8MXW26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}